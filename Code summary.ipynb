{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# MODELS\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, \\\n",
    "                                  VotingClassifier, \\\n",
    "                                  AdaBoostClassifier, BaggingRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score, \\\n",
    "                            accuracy_score, roc_auc_score, make_scorer,\\\n",
    "                            confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "# MANAGING CLASS IMBALANCE\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler # don't use this\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "# Notebook visuals\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "\n",
    "# Make better use of Jupyter Notebook cell width\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Outline**\n",
    "\n",
    "**Models**\n",
    "- Logistic Regression (or SGDClassifier if you want to do elasticnet?)\n",
    "- Naive Bayes\n",
    "- KNN\n",
    "- SVM\n",
    "- Random forest and decision trees\n",
    "- XGBoost\n",
    "\n",
    "**Data setup**\n",
    "- Feature engineering\n",
    "- Train test split\n",
    "- Stratification\n",
    "- Class imbalance\n",
    "\n",
    "**Cross validation**\n",
    "\n",
    "**Ensembling** (once you have models in place)\n",
    "\n",
    "**Model evaluation**\n",
    "- ROC/AUC\n",
    "- Precision, recall, f1 score\n",
    "- Confusion matricies\n",
    "- z score\n",
    "- f beta\n",
    "- MLE\n",
    "- Predict probas are a crucial metric to include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters you need to interrogate\n",
    "\n",
    "- KNN # neighbors\n",
    "- Logistic Regression C\n",
    "- SVM C parameter\n",
    "- Non-linear SVMs: kernel *and* gamma\n",
    "- Trees: max_depth and n_estimators\n",
    "- Ensembling: max, average, or weighted voting\n",
    "- Oversampling: random, SMOTE, or ADASYN (you don't have to get to a perfect 50/50)\n",
    "- **_threshold_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concepts to remember\n",
    "\n",
    "- Always scale/standardize except for random forest\n",
    "- Always regularize except for...\n",
    "- Do not balance your validation data (this makes using normal CV models annoying)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this info needs to be incorporated but I don't know where yet\n",
    "use special k-folds for imbalanced classes. stratified k-folds. shuffled = True\n",
    "disadvantage to lassoCV, ridgeCV, you have less control \n",
    "do a for loop to make it happen\n",
    "you can just do gridsearch cv and specify cross-validation <br> <br>\n",
    "\n",
    "If you're not sure how to pick the best threshold for your model, you can spot check by printing out the precision_recall_curve in sklearn\n",
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_test, lm.predict_proba(X_test)[:,1] )\n",
    "df = pd.DataFrame(list(zip(precision_curve, recall_curve, threshold_curve)),\n",
    "              columns=['precision','recall', 'threshhold'])\n",
    "To hone in, try generating the plot to see where a good probable threshold lies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression uses the prediction function $f(\\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1c8e83bcbd70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_per_sqft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# you can solve logistic regression with gradient descent (normal) and MLE\n",
    "\n",
    "\n",
    "# Note that the regularization term C is always present.\n",
    "# C = 0 means no regularization is happening. \n",
    "\n",
    "\n",
    "# solver options: liblinear, lbfgs\n",
    "# saga is a good solver because it works for L1 and L2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "feature = train_df[['price_per_sqft']].values\n",
    "\n",
    "lm1 = LogisticRegression(solver= 'liblinear', C=1000)\n",
    "\n",
    "lm1.fit(X_train[['elevation']], y_train)\n",
    "lm1.score(X_train[['elevation']], y_train)\n",
    "\n",
    "prediction_hard = lm1.predict(feature)\n",
    "prediction_soft = lm1.predict_proba(feature)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use masks to illustrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sf_mask = (train_df['location'] == 'SF').values\n",
    "ny_mask = (train_df['location'] == 'NY').values\n",
    "\n",
    "plt.plot(feature[sf_mask], prediction_hard[sf_mask], 'ro', label='Actually SF', alpha=0.1)\n",
    "plt.plot(feature[ny_mask], prediction_hard[ny_mask], 'bo', label='Actually NY', alpha=0.1)\n",
    "plt.xlabel('Price per square foot ($)')\n",
    "plt.ylabel('Prediction (1=SF)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use predict_proba illustrate a different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(feature[sf_mask], prediction_soft[sf_mask], 'ro', label='Actually SF', alpha = 0.1)\n",
    "plt.plot(feature[~sf_mask], prediction_soft[~sf_mask], 'bo', label='Actually NY', alpha = 0.1)\n",
    "plt.xlabel('Elevation (ft)')\n",
    "plt.ylabel('Prob of being in SF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the coefficients and the intercept to back out exactly what your \n",
    "cutoffs are by reverse engineering the log odds. Look at [this link](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1.coef_, lm1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then you can do a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, prediction_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Setting the threshold</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb = MultinomialNB()\n",
    "nb = BernoulliNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)\n",
    "nb.theta_ # mean of each feature by class\n",
    "np.sqrt(nb.sigma_) # variance of each feature by class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5) # weights is also a parameter\n",
    "knn.fit(X_train, label_train)\n",
    "print(\"The score for kNN is\")\n",
    "print(\"Training: {:6.2f}%\".format(100*knn.score(X_train, label_train)))\n",
    "print(\"Test set: {:6.2f}%\".format(100*knn.score(X_test, label_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "- The separating hyperplane is defined by the support vectors, which are the points near the plane that get moved around.\n",
    "- C is a tuning parameter. Larger C tells the model it's OK to misclassify. This is what is called using a soft margin. \n",
    "    - Usually you find C with grid search and CV\n",
    "- Gamma is a hyperparameter for non-linear kernels. It tells the model the kernel coefficient. Bigger gamma = more curviness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels: linear, poly, rbf, probably more\n",
    "# you can also change the degree with poly\n",
    "\n",
    "svm_model = svm.SVC(kernel=\"linear\")\n",
    "svm_model.fit(x, y)\n",
    "\n",
    "    \n",
    "svm_model = svm.SVC(kernel=k_name, gamma=gamma, degree=degree, C=c, cache_size=1000, max_iter=1000)\n",
    "n_sv = svm_model.support_vectors_.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"support vectors: \", svm_model.support_vectors_)\n",
    "print(\"coefficients: \", svm_model.dual_coef_)\n",
    "print(\"intercept: \", svm_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (and decision trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree = DecisionTreeClassifier(max_depth=4)\n",
    "randomforest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# n estimators is the number of trees you can grow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "- Gradient boosted decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_split_data(df, test_size=.2, seed=42):\n",
    "\n",
    "    rs = np.random.RandomState(seed)\n",
    "    \n",
    "    total_users = df['user_id'].unique() \n",
    "    test_users = rs.choice(total_users, \n",
    "                           size=int(total_users.shape[0] * test_size), \n",
    "                           replace=False)\n",
    "\n",
    "    df_tr = df[~df['user_id'].isin(test_users)]\n",
    "    df_te = df[df['user_id'].isin(test_users)] \n",
    "\n",
    "    y_tr, y_te = df_tr['in_cart'], df_te['in_cart']\n",
    "    X_tr = df_tr.drop(['product_id','user_id','latest_cart','in_cart'],axis=1) \n",
    "    X_te = df_te.drop(['product_id','user_id','latest_cart','in_cart'],axis=1)\n",
    "\n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "- Two options for the final aggregate classifier: average voting or max voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping\n",
    "- samples are chosen *with replacement*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bagging classifier through cross validation\n",
    "# ~45s to run\n",
    "# instructor: pull up the bagging classifier docs if useful\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "\n",
    "variance = []\n",
    "bias = []\n",
    "test_range = np.arange(1, 30, 1)\n",
    "\n",
    "for i in test_range:\n",
    "    cv_out = cross_validate(\n",
    "        estimator=BaggingRegressor(\n",
    "            DecisionTreeRegressor(random_state=123), n_estimators=i),\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=3,\n",
    "        return_train_score=True,\n",
    "        scoring={\n",
    "            \"variance\": make_scorer(variance_metric),\n",
    "            \"bias\": make_scorer(bias_metric)\n",
    "        },\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    variance.append(np.mean(cv_out['test_variance']))\n",
    "    bias.append(np.mean(cv_out['test_bias']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging: Hard (max), soft (averaged), and weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create voting classifier\n",
    "\n",
    "weights = [\"pick out weights for the # of models you're testing\"]\n",
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft', #<-- sklearn calls average voting \n",
    "                                    n_jobs=-1      # soft voting and max voting\n",
    "                                    weights = weights)     # not needed\n",
    "voting_classifer.fit(X_train, y_train)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = StackingClassifier(\n",
    "    classifiers=model_vars, meta_classifier=BernoulliNB(), use_probas=False)\n",
    "stacked.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance\n",
    "\n",
    "The following list is helpful when dealing with imbalanced datasets.\n",
    "\n",
    "#### Do Nothing!\n",
    "That's right, sometimes we'll get lucky and our classifier will deal effectively with the class imbalance. Go celebrate.\n",
    "\n",
    "#### Balance the dataset in some way\n",
    "- Would you run into _serious_ computational issues by doubling the amount of data you have? If so, use **Random Undersampling**\n",
    "- If you have a lot variety in your dataset, you can try **Random Oversampling** as this method will generalize well from the minority observations you currently have.\n",
    "- If Random Oversampling didn't work as well as you had hoped, try **generating synthetic data** with SMOTE or ADASYN. \n",
    "\n",
    "\n",
    "#### Switch to an Anomaly Detection Algorithm\n",
    "If the above experiments don't yield the desired results, switch to an anomaly detection algorithm (not covered in this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random oversampling, SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X,y)\n",
    "Counter(y_resampled) # to see the new distribution of the two classes\n",
    "clf_ros = SVC().fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "X_smoted, y_smoted = SMOTE(random_state=42).fit_sample(X,y)\n",
    "Counter(y_smoted) # to see the new distribution of the two classes\n",
    "clf_smote = SVC().fit(X_smoted, y_smoted)\n",
    "\n",
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_sample(X,y)\n",
    "Counter(y_adasyn)\n",
    "clf_adasyn = SVC().fit(X_adasyn, y_adasyn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "- Make sure to not balance your validation set! That means you can't use a lot of out-of-the-box CV methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=42)\n",
    "rand.fit(X, y)\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 lines of code\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores.mean())\n",
    "\n",
    "# 2 lines of code, same concept as above\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# same as above but also with a for loop to also search for # of k's\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy') # CHANGE THIS, DUDE!\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)\n",
    "\n",
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K FOLDS!!\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X, y = cars.drop('price',axis=1), cars['price']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "print(np.mean(cross_val_score(lm, X, y, cv=kf, scoring='r2')))\n",
    "print(np.mean(cross_val_score(lm_reg, X, y, cv=kf, scoring='r2')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': np.linspace(0.0, 1.0, 100)} \n",
    "# keys have to be keyword arguments allowed in the model you're trying to fit\n",
    "# e.g. double check docs that ridge uses 'alpha'\n",
    "my_model = Ridge()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "my_grid_search_ridge = GridSearchCV(my_model, param_grid, cv = 5, n_jobs = 1)\n",
    "my_grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "my_grid_search_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use consistent naming conventions for features of the same type. <br>\n",
    "*Iterate*: Build features at the same level of aggregation at the same time, and track them in a dedicated dataframe. Merge back into the ML-formatted dataframe at the end of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-off scores\n",
    "- Accuracy\n",
    "- Balanced accuracy\n",
    "- f1 and f-Beta\n",
    "- log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLE is another way of getting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = [c.predict_proba(X_train) for n,c in model_list]\n",
    "probas += [voting_model.predict_proba(X_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(model, threshold=0.5):\n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    # (model.predict(X_test) does this automatically with a threshold of 0.5)\n",
    "    y_predict = (model.predict_proba(X_test)[:, 1] >= threshold)\n",
    "    confusion_for_plot = confusion_matrix(y_test, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(confusion_for_plot, cmap=plt.cm.Blues, annot=True, square=True, fmt='d',\n",
    "           xticklabels=['legit', 'fraud'],\n",
    "           yticklabels=['legit', 'fraud']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "\n",
    "    \n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=18):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots\n",
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_test, lm.predict_proba(X_test)[:,1] )\n",
    "\n",
    "# precision recall curves separately\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.xlabel('Threshold (above this probability, label as fraud)');\n",
    "\n",
    "# precision-recall curve\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(recall_curve[1:], precision_curve[1:],label='precision')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\");\n",
    "\n",
    "# f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make a new column in 1s and 0s for classificationb\n",
    "data['Gender'] = (data['Gender'] != 'Male').astype(int)\n",
    "\n",
    "iris_df = iris_df.query(\"species > 0\")\n",
    "\n",
    "x = iris_df[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris_df.species.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_data(data):\n",
    "    plt.figure(dpi=150)\n",
    "    for ix, label in enumerate(['Male','Female']):\n",
    "        new_data = data[data['Gender']==ix]\n",
    "        plt.scatter(new_data['Height'], new_data['Weight'],c=plt.cm.jet(ix/0.5), alpha=0.4, label=label, s=5)\n",
    "    plt.ylabel(\"Weight\")\n",
    "    plt.xlabel(\"Height\")\n",
    "    plt.legend(loc=\"upper left\");\n",
    "\n",
    "scatter_plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of plotting a simple scatter plot that I haven't seen\n",
    "sns.lmplot('column1', 'column2', data=df, hue='label',\n",
    "           palette='Set2', fit_reg=False, scatter_kws={'s': 20})\n",
    "plt.gcf().set_size_inches(12,8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, lm.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for fraud problem');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_test, lm.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.support_vectors_ contains the support vectors. \n",
    "These are the same ones we found in our own solution above.\n",
    "svm_model.dual_coef_ is what we called  ùêö  \n",
    "and svm_model.intercept_ is what we called  ùëè . \n",
    "These are different in scale, but otherwise quite \n",
    "similar to what we found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial this is similar to using the PolynomialFeatures \n",
    "tool in preprocessing. It allows the model to make predictions \n",
    "based on higher order polynomial transformations of our input features.\n",
    "RBF-Radial Basis Function this is similar to selecting \n",
    "examples as prototypes of a class. The radial basis function \n",
    "decreases as a test point gets farther away from this prototype in any direction \n",
    "(thus \"radial\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'horsey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a9feee882039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# good for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Final_Time_Hund'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhorsey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'horsey' is not defined"
     ]
    }
   ],
   "source": [
    "# good for visualization \n",
    "sns.regplot('Date','Final_Time_Hund', data=horsey);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
